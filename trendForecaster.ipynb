{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "638e8a62",
   "metadata": {},
   "source": [
    "## M1: Trend Prediction - Multiclass Classification (High/Medium/Low)\n",
    "This notebook performs data fusion between weekly Google Trends and aggregated weekly weather data. \n",
    "It then trains a multiclass model to classify fashion category search interest as high, medium, or low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "68103516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in ./.venv/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in ./.venv/lib/python3.12/site-packages (from lightgbm) (2.2.5)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.12/site-packages (from lightgbm) (1.15.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lightgbm\n",
    "# Imports and Data Loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load weekly Google Trends and weather data\n",
    "trends = pd.read_parquet('./data/processed/weekly_trends.parquet')\n",
    "weather = pd.read_parquet('./data/processed/weekly_weather_agg.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d2362a",
   "metadata": {},
   "source": [
    "### Data Fusion\n",
    "\n",
    "Join Google Trends and aggregated weather data using the 'Date' field, ensuring both datasets are aligned weekly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c520c92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>locality</th>\n",
       "      <th>category</th>\n",
       "      <th>trend</th>\n",
       "      <th>avg temp °C</th>\n",
       "      <th>min temp °C</th>\n",
       "      <th>max temp °C</th>\n",
       "      <th>dew point °C</th>\n",
       "      <th>humidity %</th>\n",
       "      <th>visibility km</th>\n",
       "      <th>avg wind km/h</th>\n",
       "      <th>max wind km/h</th>\n",
       "      <th>gust km/h</th>\n",
       "      <th>slm pressure mb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>2015</td>\n",
       "      <td>53</td>\n",
       "      <td>10.0</td>\n",
       "      <td>acrylic</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>1017.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>2015</td>\n",
       "      <td>53</td>\n",
       "      <td>20.0</td>\n",
       "      <td>acrylic</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-4.666667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>84.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>2015</td>\n",
       "      <td>53</td>\n",
       "      <td>21.0</td>\n",
       "      <td>acrylic</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-4.666667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>84.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>2015</td>\n",
       "      <td>53</td>\n",
       "      <td>22.0</td>\n",
       "      <td>acrylic</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-4.666667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>84.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>2015</td>\n",
       "      <td>53</td>\n",
       "      <td>24.0</td>\n",
       "      <td>acrylic</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>97.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1018.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218715</th>\n",
       "      <td>2019</td>\n",
       "      <td>51</td>\n",
       "      <td>223.0</td>\n",
       "      <td>yellow</td>\n",
       "      <td>87.0</td>\n",
       "      <td>10.857143</td>\n",
       "      <td>8.142857</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9.428571</td>\n",
       "      <td>91.285714</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>20.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1010.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218716</th>\n",
       "      <td>2019</td>\n",
       "      <td>51</td>\n",
       "      <td>229.0</td>\n",
       "      <td>yellow</td>\n",
       "      <td>87.0</td>\n",
       "      <td>9.428571</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>12.714286</td>\n",
       "      <td>8.142857</td>\n",
       "      <td>90.142857</td>\n",
       "      <td>12.428571</td>\n",
       "      <td>9.571429</td>\n",
       "      <td>20.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1010.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218717</th>\n",
       "      <td>2019</td>\n",
       "      <td>51</td>\n",
       "      <td>238.0</td>\n",
       "      <td>yellow</td>\n",
       "      <td>87.0</td>\n",
       "      <td>12.428571</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>9.571429</td>\n",
       "      <td>81.857143</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.857143</td>\n",
       "      <td>29.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1011.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218718</th>\n",
       "      <td>2019</td>\n",
       "      <td>51</td>\n",
       "      <td>241.0</td>\n",
       "      <td>yellow</td>\n",
       "      <td>87.0</td>\n",
       "      <td>8.857143</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>10.714286</td>\n",
       "      <td>8.714286</td>\n",
       "      <td>99.142857</td>\n",
       "      <td>6.142857</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>17.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1010.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218719</th>\n",
       "      <td>2019</td>\n",
       "      <td>51</td>\n",
       "      <td>242.0</td>\n",
       "      <td>yellow</td>\n",
       "      <td>87.0</td>\n",
       "      <td>17.428571</td>\n",
       "      <td>14.857143</td>\n",
       "      <td>19.428571</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>67.857143</td>\n",
       "      <td>18.857143</td>\n",
       "      <td>22.857143</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1017.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1207008 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  week  locality category  trend  avg temp °C  min temp °C  \\\n",
       "1152     2015    53      10.0  acrylic   66.0     9.000000     4.000000   \n",
       "1154     2015    53      20.0  acrylic   66.0     0.333333    -4.666667   \n",
       "1155     2015    53      21.0  acrylic   66.0     0.333333    -4.666667   \n",
       "1156     2015    53      22.0  acrylic   66.0     0.333333    -4.666667   \n",
       "1158     2015    53      24.0  acrylic   66.0     1.333333    -0.666667   \n",
       "...       ...   ...       ...      ...    ...          ...          ...   \n",
       "1218715  2019    51     223.0   yellow   87.0    10.857143     8.142857   \n",
       "1218716  2019    51     229.0   yellow   87.0     9.428571     5.714286   \n",
       "1218717  2019    51     238.0   yellow   87.0    12.428571    10.000000   \n",
       "1218718  2019    51     241.0   yellow   87.0     8.857143     7.142857   \n",
       "1218719  2019    51     242.0   yellow   87.0    17.428571    14.857143   \n",
       "\n",
       "         max temp °C  dew point °C  humidity %  visibility km  avg wind km/h  \\\n",
       "1152       13.333333      5.666667   74.666667       9.666667      10.666667   \n",
       "1154        5.666667      0.666667   84.666667       5.333333       4.000000   \n",
       "1155        5.666667      0.666667   84.666667       5.333333       4.000000   \n",
       "1156        5.666667      0.666667   84.666667       5.333333       4.000000   \n",
       "1158        3.666667      1.333333   97.666667       2.000000       7.666667   \n",
       "...              ...           ...         ...            ...            ...   \n",
       "1218715    13.000000      9.428571   91.285714      11.142857      11.000000   \n",
       "1218716    12.714286      8.142857   90.142857      12.428571       9.571429   \n",
       "1218717    14.285714      9.571429   81.857143      15.000000      20.857143   \n",
       "1218718    10.714286      8.714286   99.142857       6.142857       8.285714   \n",
       "1218719    19.428571     11.142857   67.857143      18.857143      22.857143   \n",
       "\n",
       "         max wind km/h  gust km/h  slm pressure mb  \n",
       "1152         17.333333  17.333333      1017.666667  \n",
       "1154          7.333333   0.000000      1017.000000  \n",
       "1155          7.333333   0.000000      1017.000000  \n",
       "1156          7.333333   0.000000      1017.000000  \n",
       "1158         16.000000   0.000000      1018.333333  \n",
       "...                ...        ...              ...  \n",
       "1218715      20.285714   0.000000      1010.714286  \n",
       "1218716      20.142857   0.000000      1010.428571  \n",
       "1218717      29.714286   0.000000      1011.857143  \n",
       "1218718      17.428571   0.000000      1010.285714  \n",
       "1218719      36.000000   0.000000      1017.000000  \n",
       "\n",
       "[1207008 rows x 15 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge trends and weather data on the 'date' field\n",
    "df = trends.merge(weather, on='date', how='left')\n",
    "\n",
    "# Keep only one 'year' and one 'week' column\n",
    "df['year'] = df['year_x']\n",
    "df['week'] = df['week_x']\n",
    "df = df.drop(columns=['year_x', 'week_x', 'year_y', 'week_y'])\n",
    "\n",
    "# Drop rows with any missing data\n",
    "df = df.dropna()\n",
    "\n",
    "# Drop 'date' column\n",
    "df = df.drop(columns=['date'])\n",
    "\n",
    "# Reorder columns: year, week, date, then all others\n",
    "first_cols = ['year', 'week', 'locality']\n",
    "other_cols = [col for col in df.columns if col not in first_cols]\n",
    "df = df[first_cols + other_cols]\n",
    "\n",
    "df = df.drop(columns=['avg pressure mb', 'rain mm'])\n",
    "\n",
    "# Check result\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f780a2",
   "metadata": {},
   "source": [
    "### Category Encoding\n",
    "\n",
    "Map each category string to a numeric category_id for machine learning compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "25cdf67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>locality</th>\n",
       "      <th>category</th>\n",
       "      <th>trend</th>\n",
       "      <th>avg temp °C</th>\n",
       "      <th>min temp °C</th>\n",
       "      <th>max temp °C</th>\n",
       "      <th>dew point °C</th>\n",
       "      <th>humidity %</th>\n",
       "      <th>visibility km</th>\n",
       "      <th>avg wind km/h</th>\n",
       "      <th>max wind km/h</th>\n",
       "      <th>gust km/h</th>\n",
       "      <th>slm pressure mb</th>\n",
       "      <th>category_norm</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>2015</td>\n",
       "      <td>53</td>\n",
       "      <td>10.0</td>\n",
       "      <td>acrylic</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>1017.666667</td>\n",
       "      <td>acrylic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>2015</td>\n",
       "      <td>53</td>\n",
       "      <td>20.0</td>\n",
       "      <td>acrylic</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-4.666667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>84.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1017.000000</td>\n",
       "      <td>acrylic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>2015</td>\n",
       "      <td>53</td>\n",
       "      <td>21.0</td>\n",
       "      <td>acrylic</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-4.666667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>84.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1017.000000</td>\n",
       "      <td>acrylic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>2015</td>\n",
       "      <td>53</td>\n",
       "      <td>22.0</td>\n",
       "      <td>acrylic</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-4.666667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>84.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1017.000000</td>\n",
       "      <td>acrylic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>2015</td>\n",
       "      <td>53</td>\n",
       "      <td>24.0</td>\n",
       "      <td>acrylic</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>97.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1018.333333</td>\n",
       "      <td>acrylic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218715</th>\n",
       "      <td>2019</td>\n",
       "      <td>51</td>\n",
       "      <td>223.0</td>\n",
       "      <td>yellow</td>\n",
       "      <td>87.0</td>\n",
       "      <td>10.857143</td>\n",
       "      <td>8.142857</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9.428571</td>\n",
       "      <td>91.285714</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>20.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1010.714286</td>\n",
       "      <td>yellow</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218716</th>\n",
       "      <td>2019</td>\n",
       "      <td>51</td>\n",
       "      <td>229.0</td>\n",
       "      <td>yellow</td>\n",
       "      <td>87.0</td>\n",
       "      <td>9.428571</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>12.714286</td>\n",
       "      <td>8.142857</td>\n",
       "      <td>90.142857</td>\n",
       "      <td>12.428571</td>\n",
       "      <td>9.571429</td>\n",
       "      <td>20.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1010.428571</td>\n",
       "      <td>yellow</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218717</th>\n",
       "      <td>2019</td>\n",
       "      <td>51</td>\n",
       "      <td>238.0</td>\n",
       "      <td>yellow</td>\n",
       "      <td>87.0</td>\n",
       "      <td>12.428571</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>9.571429</td>\n",
       "      <td>81.857143</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.857143</td>\n",
       "      <td>29.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1011.857143</td>\n",
       "      <td>yellow</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218718</th>\n",
       "      <td>2019</td>\n",
       "      <td>51</td>\n",
       "      <td>241.0</td>\n",
       "      <td>yellow</td>\n",
       "      <td>87.0</td>\n",
       "      <td>8.857143</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>10.714286</td>\n",
       "      <td>8.714286</td>\n",
       "      <td>99.142857</td>\n",
       "      <td>6.142857</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>17.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1010.285714</td>\n",
       "      <td>yellow</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218719</th>\n",
       "      <td>2019</td>\n",
       "      <td>51</td>\n",
       "      <td>242.0</td>\n",
       "      <td>yellow</td>\n",
       "      <td>87.0</td>\n",
       "      <td>17.428571</td>\n",
       "      <td>14.857143</td>\n",
       "      <td>19.428571</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>67.857143</td>\n",
       "      <td>18.857143</td>\n",
       "      <td>22.857143</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1017.000000</td>\n",
       "      <td>yellow</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1207008 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  week  locality category  trend  avg temp °C  min temp °C  \\\n",
       "1152     2015    53      10.0  acrylic   66.0     9.000000     4.000000   \n",
       "1154     2015    53      20.0  acrylic   66.0     0.333333    -4.666667   \n",
       "1155     2015    53      21.0  acrylic   66.0     0.333333    -4.666667   \n",
       "1156     2015    53      22.0  acrylic   66.0     0.333333    -4.666667   \n",
       "1158     2015    53      24.0  acrylic   66.0     1.333333    -0.666667   \n",
       "...       ...   ...       ...      ...    ...          ...          ...   \n",
       "1218715  2019    51     223.0   yellow   87.0    10.857143     8.142857   \n",
       "1218716  2019    51     229.0   yellow   87.0     9.428571     5.714286   \n",
       "1218717  2019    51     238.0   yellow   87.0    12.428571    10.000000   \n",
       "1218718  2019    51     241.0   yellow   87.0     8.857143     7.142857   \n",
       "1218719  2019    51     242.0   yellow   87.0    17.428571    14.857143   \n",
       "\n",
       "         max temp °C  dew point °C  humidity %  visibility km  avg wind km/h  \\\n",
       "1152       13.333333      5.666667   74.666667       9.666667      10.666667   \n",
       "1154        5.666667      0.666667   84.666667       5.333333       4.000000   \n",
       "1155        5.666667      0.666667   84.666667       5.333333       4.000000   \n",
       "1156        5.666667      0.666667   84.666667       5.333333       4.000000   \n",
       "1158        3.666667      1.333333   97.666667       2.000000       7.666667   \n",
       "...              ...           ...         ...            ...            ...   \n",
       "1218715    13.000000      9.428571   91.285714      11.142857      11.000000   \n",
       "1218716    12.714286      8.142857   90.142857      12.428571       9.571429   \n",
       "1218717    14.285714      9.571429   81.857143      15.000000      20.857143   \n",
       "1218718    10.714286      8.714286   99.142857       6.142857       8.285714   \n",
       "1218719    19.428571     11.142857   67.857143      18.857143      22.857143   \n",
       "\n",
       "         max wind km/h  gust km/h  slm pressure mb category_norm  category_id  \n",
       "1152         17.333333  17.333333      1017.666667       acrylic            0  \n",
       "1154          7.333333   0.000000      1017.000000       acrylic            0  \n",
       "1155          7.333333   0.000000      1017.000000       acrylic            0  \n",
       "1156          7.333333   0.000000      1017.000000       acrylic            0  \n",
       "1158         16.000000   0.000000      1018.333333       acrylic            0  \n",
       "...                ...        ...              ...           ...          ...  \n",
       "1218715      20.285714   0.000000      1010.714286        yellow           95  \n",
       "1218716      20.142857   0.000000      1010.428571        yellow           95  \n",
       "1218717      29.714286   0.000000      1011.857143        yellow           95  \n",
       "1218718      17.428571   0.000000      1010.285714        yellow           95  \n",
       "1218719      36.000000   0.000000      1017.000000        yellow           95  \n",
       "\n",
       "[1207008 rows x 17 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create consistent category mapping\n",
    "categories = sorted(df['category'].dropna().str.lower().str.strip().unique())\n",
    "category2id = {cat: i for i, cat in enumerate(categories)}\n",
    "category2id['unknown'] = -1\n",
    "\n",
    "# Normalize category text and map\n",
    "df['category_norm'] = df['category'].str.lower().str.strip()\n",
    "df['category_id'] = df['category_norm'].map(category2id).fillna(-1).astype(int)\n",
    "\n",
    "# Save the category encoding mapping into a file\n",
    "torch.save(category2id, './data/processed/category2id.pt')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b299fb51",
   "metadata": {},
   "source": [
    "### Target Engineering\n",
    "\n",
    "Assign three classes: \n",
    "- 2 = high (trend > 75th percentile)\n",
    "- 1 = medium (trend between 50th and 75th percentile)\n",
    "- 0 = low  (trend ≤ 50th percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b0b39c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trend_class\n",
      "0    604126\n",
      "1    313099\n",
      "2    289783\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define percentiles\n",
    "q50 = df['trend'].quantile(0.50)\n",
    "q75 = df['trend'].quantile(0.75)\n",
    "\n",
    "def trend_class(trend):\n",
    "    if trend > q75:\n",
    "        return 2 # high\n",
    "    elif trend > q50:\n",
    "        return 1 # medium\n",
    "    else:\n",
    "        return 0 # low\n",
    "\n",
    "df['trend_class'] = df['trend'].apply(trend_class)\n",
    "print(df['trend_class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b6aa5513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trend_class_category         0         1         2\n",
      "category_id                                       \n",
      "0                     0.533365  0.216655  0.249980\n",
      "1                     0.510061  0.274636  0.215303\n",
      "2                     0.500358  0.259922  0.239720\n",
      "3                     0.557146  0.270023  0.172831\n",
      "4                     0.543307  0.226358  0.230335\n",
      "...                        ...       ...       ...\n",
      "91                    0.523741  0.264058  0.212201\n",
      "92                    0.750020  0.000000  0.249980\n",
      "93                    0.538296  0.244969  0.216734\n",
      "94                    0.505130  0.317665  0.177205\n",
      "95                    0.529627  0.225324  0.245049\n",
      "\n",
      "[96 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "exclude = ['year', 'week', 'category', 'date', 'trend', 'trend_class', 'category_norm']  # aggiungi qui tutto ciò che vuoi escludere\n",
    "feature_cols = [col for col in df.columns if col not in exclude]\n",
    "X = df[feature_cols]\n",
    "# Calcola i quantili \"per category_id\"\n",
    "def assign_trend_class(row, qtable):\n",
    "    q50 = qtable.loc[row['category_id'], 0.5]\n",
    "    q75 = qtable.loc[row['category_id'], 0.75]\n",
    "    if row['trend'] > q75:\n",
    "        return 2  # high\n",
    "    elif row['trend'] > q50:\n",
    "        return 1  # medium\n",
    "    else:\n",
    "        return 0  # low\n",
    "\n",
    "# Crea la tabella dei quantili per ogni categoria\n",
    "qtable = df.groupby('category_id')['trend'].quantile([0.5, 0.75]).unstack(level=-1)\n",
    "\n",
    "# Applica la funzione riga per riga (usa qtable di sopra)\n",
    "df['trend_class_category'] = df.apply(lambda row: assign_trend_class(row, qtable), axis=1)\n",
    "\n",
    "# Controlla la nuova distribuzione (più bilanciata)\n",
    "dist_cat = df.groupby('category_id')['trend_class_category'].value_counts(normalize=True).unstack(fill_value=0)\n",
    "print(dist_cat)\n",
    "\n",
    "# Puoi usarla ora come nuovo target:\n",
    "y = df['trend_class_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2498e395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>trend_class_category</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.533365</td>\n",
       "      <td>0.216655</td>\n",
       "      <td>0.249980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.510061</td>\n",
       "      <td>0.274636</td>\n",
       "      <td>0.215303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500358</td>\n",
       "      <td>0.259922</td>\n",
       "      <td>0.239720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.557146</td>\n",
       "      <td>0.270023</td>\n",
       "      <td>0.172831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.543307</td>\n",
       "      <td>0.226358</td>\n",
       "      <td>0.230335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.520719</td>\n",
       "      <td>0.231289</td>\n",
       "      <td>0.247992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.523503</td>\n",
       "      <td>0.312734</td>\n",
       "      <td>0.163764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.508232</td>\n",
       "      <td>0.250219</td>\n",
       "      <td>0.241549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.519208</td>\n",
       "      <td>0.273602</td>\n",
       "      <td>0.207190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.625467</td>\n",
       "      <td>0.129722</td>\n",
       "      <td>0.244810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.509584</td>\n",
       "      <td>0.240674</td>\n",
       "      <td>0.249742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.533604</td>\n",
       "      <td>0.255309</td>\n",
       "      <td>0.211087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.567645</td>\n",
       "      <td>0.201941</td>\n",
       "      <td>0.230414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.586336</td>\n",
       "      <td>0.225324</td>\n",
       "      <td>0.188340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.508630</td>\n",
       "      <td>0.259922</td>\n",
       "      <td>0.231448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.909648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.514992</td>\n",
       "      <td>0.240197</td>\n",
       "      <td>0.244810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.548477</td>\n",
       "      <td>0.216814</td>\n",
       "      <td>0.234709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.500040</td>\n",
       "      <td>0.250139</td>\n",
       "      <td>0.249821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.538694</td>\n",
       "      <td>0.225960</td>\n",
       "      <td>0.235346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.514356</td>\n",
       "      <td>0.235743</td>\n",
       "      <td>0.249901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.525650</td>\n",
       "      <td>0.234789</td>\n",
       "      <td>0.239561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.542830</td>\n",
       "      <td>0.231051</td>\n",
       "      <td>0.226119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.557464</td>\n",
       "      <td>0.236061</td>\n",
       "      <td>0.206474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.557385</td>\n",
       "      <td>0.206713</td>\n",
       "      <td>0.235902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.264217</td>\n",
       "      <td>0.210531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.500437</td>\n",
       "      <td>0.249901</td>\n",
       "      <td>0.249662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.565975</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>0.222620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.980593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.534558</td>\n",
       "      <td>0.226040</td>\n",
       "      <td>0.239402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.544898</td>\n",
       "      <td>0.221188</td>\n",
       "      <td>0.233914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.524457</td>\n",
       "      <td>0.226199</td>\n",
       "      <td>0.249344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.518174</td>\n",
       "      <td>0.236300</td>\n",
       "      <td>0.245526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.528752</td>\n",
       "      <td>0.250378</td>\n",
       "      <td>0.220870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.524139</td>\n",
       "      <td>0.240277</td>\n",
       "      <td>0.235584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.538296</td>\n",
       "      <td>0.235425</td>\n",
       "      <td>0.226279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.519606</td>\n",
       "      <td>0.254673</td>\n",
       "      <td>0.225722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.518094</td>\n",
       "      <td>0.264376</td>\n",
       "      <td>0.217530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.533922</td>\n",
       "      <td>0.234948</td>\n",
       "      <td>0.231130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.519446</td>\n",
       "      <td>0.239561</td>\n",
       "      <td>0.240993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.509584</td>\n",
       "      <td>0.245049</td>\n",
       "      <td>0.245367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.535194</td>\n",
       "      <td>0.229619</td>\n",
       "      <td>0.235187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.501153</td>\n",
       "      <td>0.249582</td>\n",
       "      <td>0.249264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.523503</td>\n",
       "      <td>0.231210</td>\n",
       "      <td>0.245288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.500835</td>\n",
       "      <td>0.250219</td>\n",
       "      <td>0.248946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.525014</td>\n",
       "      <td>0.239720</td>\n",
       "      <td>0.235266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.533683</td>\n",
       "      <td>0.216814</td>\n",
       "      <td>0.249503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.504732</td>\n",
       "      <td>0.255707</td>\n",
       "      <td>0.239561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.504971</td>\n",
       "      <td>0.259286</td>\n",
       "      <td>0.235743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.504096</td>\n",
       "      <td>0.250935</td>\n",
       "      <td>0.244969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.513561</td>\n",
       "      <td>0.283544</td>\n",
       "      <td>0.202895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.562714</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.245367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.505210</td>\n",
       "      <td>0.269148</td>\n",
       "      <td>0.225642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.716695</td>\n",
       "      <td>0.081763</td>\n",
       "      <td>0.201543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.500040</td>\n",
       "      <td>0.259843</td>\n",
       "      <td>0.240118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.506403</td>\n",
       "      <td>0.248389</td>\n",
       "      <td>0.245208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.508789</td>\n",
       "      <td>0.264694</td>\n",
       "      <td>0.226517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.677802</td>\n",
       "      <td>0.182773</td>\n",
       "      <td>0.139426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.524378</td>\n",
       "      <td>0.240356</td>\n",
       "      <td>0.235266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.553090</td>\n",
       "      <td>0.235107</td>\n",
       "      <td>0.211803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.530343</td>\n",
       "      <td>0.239640</td>\n",
       "      <td>0.230017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.529627</td>\n",
       "      <td>0.246083</td>\n",
       "      <td>0.224290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.562555</td>\n",
       "      <td>0.192396</td>\n",
       "      <td>0.245049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.537581</td>\n",
       "      <td>0.274079</td>\n",
       "      <td>0.188340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.510061</td>\n",
       "      <td>0.258968</td>\n",
       "      <td>0.230971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.515390</td>\n",
       "      <td>0.249662</td>\n",
       "      <td>0.234948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.588086</td>\n",
       "      <td>0.182534</td>\n",
       "      <td>0.229380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.519526</td>\n",
       "      <td>0.302871</td>\n",
       "      <td>0.177603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.633421</td>\n",
       "      <td>0.202656</td>\n",
       "      <td>0.163923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.514118</td>\n",
       "      <td>0.249105</td>\n",
       "      <td>0.236777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.557226</td>\n",
       "      <td>0.230971</td>\n",
       "      <td>0.211803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.509902</td>\n",
       "      <td>0.259206</td>\n",
       "      <td>0.230892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.518890</td>\n",
       "      <td>0.249742</td>\n",
       "      <td>0.231369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.634375</td>\n",
       "      <td>0.154219</td>\n",
       "      <td>0.211405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.500199</td>\n",
       "      <td>0.263978</td>\n",
       "      <td>0.235823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.505607</td>\n",
       "      <td>0.258490</td>\n",
       "      <td>0.235902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.515311</td>\n",
       "      <td>0.239959</td>\n",
       "      <td>0.244731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.508391</td>\n",
       "      <td>0.255468</td>\n",
       "      <td>0.236141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.528911</td>\n",
       "      <td>0.229937</td>\n",
       "      <td>0.241152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.508709</td>\n",
       "      <td>0.250616</td>\n",
       "      <td>0.240674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.513720</td>\n",
       "      <td>0.249264</td>\n",
       "      <td>0.237016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.250139</td>\n",
       "      <td>0.244810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.519287</td>\n",
       "      <td>0.240674</td>\n",
       "      <td>0.240038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.581723</td>\n",
       "      <td>0.182614</td>\n",
       "      <td>0.235664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.259843</td>\n",
       "      <td>0.235107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.505846</td>\n",
       "      <td>0.253241</td>\n",
       "      <td>0.240913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.567088</td>\n",
       "      <td>0.192635</td>\n",
       "      <td>0.240277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.523741</td>\n",
       "      <td>0.245367</td>\n",
       "      <td>0.230892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.523741</td>\n",
       "      <td>0.264058</td>\n",
       "      <td>0.212201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.750020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.538296</td>\n",
       "      <td>0.244969</td>\n",
       "      <td>0.216734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.505130</td>\n",
       "      <td>0.317665</td>\n",
       "      <td>0.177205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.529627</td>\n",
       "      <td>0.225324</td>\n",
       "      <td>0.245049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "trend_class_category         0         1         2\n",
       "category_id                                       \n",
       "0                     0.533365  0.216655  0.249980\n",
       "1                     0.510061  0.274636  0.215303\n",
       "2                     0.500358  0.259922  0.239720\n",
       "3                     0.557146  0.270023  0.172831\n",
       "4                     0.543307  0.226358  0.230335\n",
       "5                     0.520719  0.231289  0.247992\n",
       "6                     0.523503  0.312734  0.163764\n",
       "7                     0.508232  0.250219  0.241549\n",
       "8                     0.519208  0.273602  0.207190\n",
       "9                     0.625467  0.129722  0.244810\n",
       "10                    0.509584  0.240674  0.249742\n",
       "11                    0.533604  0.255309  0.211087\n",
       "12                    0.567645  0.201941  0.230414\n",
       "13                    0.586336  0.225324  0.188340\n",
       "14                    0.508630  0.259922  0.231448\n",
       "15                    0.909648  0.000000  0.090352\n",
       "16                    0.514992  0.240197  0.244810\n",
       "17                    0.548477  0.216814  0.234709\n",
       "18                    0.500040  0.250139  0.249821\n",
       "19                    0.538694  0.225960  0.235346\n",
       "20                    0.514356  0.235743  0.249901\n",
       "21                    0.525650  0.234789  0.239561\n",
       "22                    0.542830  0.231051  0.226119\n",
       "23                    0.557464  0.236061  0.206474\n",
       "24                    1.000000  0.000000  0.000000\n",
       "25                    0.557385  0.206713  0.235902\n",
       "26                    0.525253  0.264217  0.210531\n",
       "27                    0.500437  0.249901  0.249662\n",
       "28                    0.565975  0.211405  0.222620\n",
       "29                    0.980593  0.000000  0.019407\n",
       "30                    0.534558  0.226040  0.239402\n",
       "31                    0.544898  0.221188  0.233914\n",
       "32                    0.524457  0.226199  0.249344\n",
       "33                    0.518174  0.236300  0.245526\n",
       "34                    0.528752  0.250378  0.220870\n",
       "35                    0.524139  0.240277  0.235584\n",
       "36                    0.538296  0.235425  0.226279\n",
       "37                    0.519606  0.254673  0.225722\n",
       "38                    0.518094  0.264376  0.217530\n",
       "39                    0.533922  0.234948  0.231130\n",
       "40                    0.519446  0.239561  0.240993\n",
       "41                    0.509584  0.245049  0.245367\n",
       "42                    0.535194  0.229619  0.235187\n",
       "43                    0.501153  0.249582  0.249264\n",
       "44                    0.523503  0.231210  0.245288\n",
       "45                    0.500835  0.250219  0.248946\n",
       "46                    0.525014  0.239720  0.235266\n",
       "47                    0.533683  0.216814  0.249503\n",
       "48                    0.504732  0.255707  0.239561\n",
       "49                    0.504971  0.259286  0.235743\n",
       "50                    0.504096  0.250935  0.244969\n",
       "51                    0.513561  0.283544  0.202895\n",
       "52                    0.562714  0.191919  0.245367\n",
       "53                    0.505210  0.269148  0.225642\n",
       "54                    0.716695  0.081763  0.201543\n",
       "55                    0.500040  0.259843  0.240118\n",
       "56                    0.506403  0.248389  0.245208\n",
       "57                    1.000000  0.000000  0.000000\n",
       "58                    0.508789  0.264694  0.226517\n",
       "59                    0.677802  0.182773  0.139426\n",
       "60                    0.524378  0.240356  0.235266\n",
       "61                    0.553090  0.235107  0.211803\n",
       "62                    0.530343  0.239640  0.230017\n",
       "63                    0.529627  0.246083  0.224290\n",
       "64                    0.562555  0.192396  0.245049\n",
       "65                    0.537581  0.274079  0.188340\n",
       "66                    0.510061  0.258968  0.230971\n",
       "67                    0.515390  0.249662  0.234948\n",
       "68                    0.588086  0.182534  0.229380\n",
       "69                    1.000000  0.000000  0.000000\n",
       "70                    0.519526  0.302871  0.177603\n",
       "71                    0.633421  0.202656  0.163923\n",
       "72                    0.514118  0.249105  0.236777\n",
       "73                    0.557226  0.230971  0.211803\n",
       "74                    0.509902  0.259206  0.230892\n",
       "75                    0.518890  0.249742  0.231369\n",
       "76                    0.634375  0.154219  0.211405\n",
       "77                    0.500199  0.263978  0.235823\n",
       "78                    0.505607  0.258490  0.235902\n",
       "79                    0.515311  0.239959  0.244731\n",
       "80                    0.508391  0.255468  0.236141\n",
       "81                    0.528911  0.229937  0.241152\n",
       "82                    0.508709  0.250616  0.240674\n",
       "83                    0.513720  0.249264  0.237016\n",
       "84                    0.505051  0.250139  0.244810\n",
       "85                    0.519287  0.240674  0.240038\n",
       "86                    0.581723  0.182614  0.235664\n",
       "87                    0.505051  0.259843  0.235107\n",
       "88                    0.505846  0.253241  0.240913\n",
       "89                    0.567088  0.192635  0.240277\n",
       "90                    0.523741  0.245367  0.230892\n",
       "91                    0.523741  0.264058  0.212201\n",
       "92                    0.750020  0.000000  0.249980\n",
       "93                    0.538296  0.244969  0.216734\n",
       "94                    0.505130  0.317665  0.177205\n",
       "95                    0.529627  0.225324  0.245049"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Group by category_id and show distribution for trend_class_category\n",
    "dist_cat = df.groupby('category_id')['trend_class_category'].value_counts(normalize=True).unstack(fill_value=0)\n",
    "\n",
    "# Stacked bar plot for the first 10 categories\n",
    "dist_cat.head(10).plot(kind='bar', stacked=True, colormap='viridis', figsize=(10,6))\n",
    "plt.title('Distribuzione delle classi di trend (per categoria, con quantili locali)')\n",
    "plt.xlabel('category_id')\n",
    "plt.ylabel('Fraction per trend_class_category')\n",
    "plt.legend(['Low', 'Medium', 'High'], title='Trend Class')\n",
    "plt.show()\n",
    "\n",
    "# (Optional) Show the entire table (increase pandas display options if needed)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "display(dist_cat)\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9567dd",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "Split the data into training and test sets, while preserving the distribution of the target classes using stratification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "902aa0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (965606, 12)\n",
      "Test set size: (241402, 12)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.20, random_state=42\n",
    ")\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "print(\"Train set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8207f58c",
   "metadata": {},
   "source": [
    "### LightGBM Modeling with GridSearchCV and Optuna Hyperparameter Tuning\n",
    "\n",
    "In this step, we train a LightGBM classifier using cross-validation and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "784216cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a05c74f",
   "metadata": {},
   "source": [
    "#### Optuna Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "87312fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:07:34,633] A new study created in memory with name: no-name-dfa13cd2-f293-4e09-9f66-cda63f93eed5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8504807487571215, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8504807487571215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9507010239474184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9507010239474184\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8504807487571215, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8504807487571215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9507010239474184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9507010239474184\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8504807487571215, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8504807487571215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9507010239474184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9507010239474184\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8504807487571215, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8504807487571215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9507010239474184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9507010239474184\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8504807487571215, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8504807487571215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9507010239474184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9507010239474184\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8504807487571215, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8504807487571215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9507010239474184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9507010239474184\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8504807487571215, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8504807487571215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9507010239474184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9507010239474184\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8504807487571215, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8504807487571215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9507010239474184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9507010239474184\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8504807487571215, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8504807487571215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9507010239474184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9507010239474184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:09:29,059] Trial 0 finished with value: 0.6234433333333333 and parameters: {'num_leaves': 171, 'learning_rate': 0.27520334268618035, 'n_estimators': 473, 'max_depth': 14, 'feature_fraction': 0.8504807487571215, 'bagging_fraction': 0.9507010239474184, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 0 with value: 0.6234433333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9045962488118905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9045962488118905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9233378478666971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9233378478666971\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9045962488118905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9045962488118905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9233378478666971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9233378478666971\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9045962488118905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9045962488118905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9233378478666971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9233378478666971\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9045962488118905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9045962488118905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9233378478666971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9233378478666971\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9045962488118905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9045962488118905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9233378478666971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9233378478666971\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9045962488118905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9045962488118905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9233378478666971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9233378478666971\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9045962488118905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9045962488118905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9233378478666971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9233378478666971\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9045962488118905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9045962488118905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9233378478666971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9233378478666971\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9045962488118905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9045962488118905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9233378478666971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9233378478666971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:11:26,155] Trial 1 finished with value: 0.6285633333333333 and parameters: {'num_leaves': 183, 'learning_rate': 0.22192929074006237, 'n_estimators': 467, 'max_depth': 15, 'feature_fraction': 0.9045962488118905, 'bagging_fraction': 0.9233378478666971, 'bagging_freq': 2, 'min_child_samples': 33}. Best is trial 1 with value: 0.6285633333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8875757368916395, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8875757368916395\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9593586568744893, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9593586568744893\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8875757368916395, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8875757368916395\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9593586568744893, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9593586568744893\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8875757368916395, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8875757368916395\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9593586568744893, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9593586568744893\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8875757368916395, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8875757368916395\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9593586568744893, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9593586568744893\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8875757368916395, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8875757368916395\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9593586568744893, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9593586568744893\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8875757368916395, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8875757368916395\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9593586568744893, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9593586568744893\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8875757368916395, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8875757368916395\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9593586568744893, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9593586568744893\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8875757368916395, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8875757368916395\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9593586568744893, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9593586568744893\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8875757368916395, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8875757368916395\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9593586568744893, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9593586568744893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:13:37,119] Trial 2 finished with value: 0.6257833333333332 and parameters: {'num_leaves': 196, 'learning_rate': 0.2571564436012403, 'n_estimators': 517, 'max_depth': 17, 'feature_fraction': 0.8875757368916395, 'bagging_fraction': 0.9593586568744893, 'bagging_freq': 4, 'min_child_samples': 65}. Best is trial 1 with value: 0.6285633333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8838255245301813, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8838255245301813\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9569456851218924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9569456851218924\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8838255245301813, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8838255245301813\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9569456851218924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9569456851218924\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8838255245301813, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8838255245301813\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9569456851218924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9569456851218924\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8838255245301813, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8838255245301813\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9569456851218924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9569456851218924\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8838255245301813, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8838255245301813\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9569456851218924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9569456851218924\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8838255245301813, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8838255245301813\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9569456851218924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9569456851218924\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8838255245301813, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8838255245301813\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9569456851218924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9569456851218924\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8838255245301813, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8838255245301813\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9569456851218924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9569456851218924\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8838255245301813, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8838255245301813\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9569456851218924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9569456851218924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:15:28,404] Trial 3 finished with value: 0.63054 and parameters: {'num_leaves': 174, 'learning_rate': 0.22721174530424523, 'n_estimators': 490, 'max_depth': 14, 'feature_fraction': 0.8838255245301813, 'bagging_fraction': 0.9569456851218924, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 3 with value: 0.63054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8566667250546238, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8566667250546238\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9256079982151615, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9256079982151615\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8566667250546238, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8566667250546238\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9256079982151615, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9256079982151615\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8566667250546238, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8566667250546238\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9256079982151615, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9256079982151615\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8566667250546238, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8566667250546238\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9256079982151615, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9256079982151615\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8566667250546238, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8566667250546238\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9256079982151615, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9256079982151615\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8566667250546238, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8566667250546238\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9256079982151615, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9256079982151615\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8566667250546238, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8566667250546238\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9256079982151615, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9256079982151615\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8566667250546238, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8566667250546238\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9256079982151615, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9256079982151615\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8566667250546238, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8566667250546238\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9256079982151615, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9256079982151615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:17:42,391] Trial 4 finished with value: 0.6282033333333334 and parameters: {'num_leaves': 207, 'learning_rate': 0.23908203465330247, 'n_estimators': 499, 'max_depth': 13, 'feature_fraction': 0.8566667250546238, 'bagging_fraction': 0.9256079982151615, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 3 with value: 0.63054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8953946849614731, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8953946849614731\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9306343730379185, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9306343730379185\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8953946849614731, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8953946849614731\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9306343730379185, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9306343730379185\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8953946849614731, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8953946849614731\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9306343730379185, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9306343730379185\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8953946849614731, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8953946849614731\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9306343730379185, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9306343730379185\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8953946849614731, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8953946849614731\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9306343730379185, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9306343730379185\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8953946849614731, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8953946849614731\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9306343730379185, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9306343730379185\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8953946849614731, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8953946849614731\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9306343730379185, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9306343730379185\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8953946849614731, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8953946849614731\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9306343730379185, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9306343730379185\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8953946849614731, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8953946849614731\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9306343730379185, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9306343730379185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:19:47,104] Trial 5 finished with value: 0.6198199999999999 and parameters: {'num_leaves': 203, 'learning_rate': 0.22076128886031937, 'n_estimators': 451, 'max_depth': 14, 'feature_fraction': 0.8953946849614731, 'bagging_fraction': 0.9306343730379185, 'bagging_freq': 4, 'min_child_samples': 67}. Best is trial 3 with value: 0.63054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9134158967905728, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9134158967905728\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9795338445895466, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9795338445895466\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9134158967905728, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9134158967905728\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9795338445895466, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9795338445895466\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9134158967905728, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9134158967905728\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9795338445895466, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9795338445895466\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9134158967905728, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9134158967905728\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9795338445895466, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9795338445895466\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9134158967905728, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9134158967905728\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9795338445895466, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9795338445895466\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9134158967905728, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9134158967905728\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9795338445895466, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9795338445895466\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9134158967905728, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9134158967905728\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9795338445895466, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9795338445895466\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9134158967905728, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9134158967905728\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9795338445895466, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9795338445895466\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9134158967905728, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9134158967905728\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9795338445895466, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9795338445895466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:21:44,431] Trial 6 finished with value: 0.62093 and parameters: {'num_leaves': 175, 'learning_rate': 0.24085584147461972, 'n_estimators': 476, 'max_depth': 14, 'feature_fraction': 0.9134158967905728, 'bagging_fraction': 0.9795338445895466, 'bagging_freq': 3, 'min_child_samples': 75}. Best is trial 3 with value: 0.63054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8959861227075734, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8959861227075734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9267337744597628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9267337744597628\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8959861227075734, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8959861227075734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9267337744597628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9267337744597628\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8959861227075734, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8959861227075734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9267337744597628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9267337744597628\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8959861227075734, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8959861227075734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9267337744597628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9267337744597628\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8959861227075734, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8959861227075734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9267337744597628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9267337744597628\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8959861227075734, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8959861227075734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9267337744597628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9267337744597628\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8959861227075734, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8959861227075734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9267337744597628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9267337744597628\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8959861227075734, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8959861227075734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9267337744597628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9267337744597628\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8959861227075734, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8959861227075734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9267337744597628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9267337744597628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:23:47,817] Trial 7 finished with value: 0.6290366666666667 and parameters: {'num_leaves': 196, 'learning_rate': 0.2231227824709338, 'n_estimators': 475, 'max_depth': 17, 'feature_fraction': 0.8959861227075734, 'bagging_fraction': 0.9267337744597628, 'bagging_freq': 2, 'min_child_samples': 36}. Best is trial 3 with value: 0.63054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8768534509181365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8768534509181365\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9542073061815891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9542073061815891\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8768534509181365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8768534509181365\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9542073061815891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9542073061815891\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8768534509181365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8768534509181365\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9542073061815891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9542073061815891\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8768534509181365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8768534509181365\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9542073061815891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9542073061815891\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8768534509181365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8768534509181365\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9542073061815891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9542073061815891\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8768534509181365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8768534509181365\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9542073061815891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9542073061815891\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8768534509181365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8768534509181365\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9542073061815891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9542073061815891\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8768534509181365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8768534509181365\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9542073061815891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9542073061815891\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8768534509181365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8768534509181365\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9542073061815891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9542073061815891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:25:38,104] Trial 8 finished with value: 0.6352566666666667 and parameters: {'num_leaves': 190, 'learning_rate': 0.2224801562758738, 'n_estimators': 461, 'max_depth': 14, 'feature_fraction': 0.8768534509181365, 'bagging_fraction': 0.9542073061815891, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 8 with value: 0.6352566666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8585713056119598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8585713056119598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9420445160537261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9420445160537261\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8585713056119598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8585713056119598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9420445160537261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9420445160537261\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8585713056119598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8585713056119598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9420445160537261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9420445160537261\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8585713056119598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8585713056119598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9420445160537261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9420445160537261\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8585713056119598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8585713056119598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9420445160537261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9420445160537261\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8585713056119598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8585713056119598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9420445160537261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9420445160537261\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8585713056119598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8585713056119598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9420445160537261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9420445160537261\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8585713056119598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8585713056119598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9420445160537261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9420445160537261\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8585713056119598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8585713056119598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9420445160537261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9420445160537261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:27:45,885] Trial 9 finished with value: 0.61823 and parameters: {'num_leaves': 172, 'learning_rate': 0.28214946586792883, 'n_estimators': 499, 'max_depth': 14, 'feature_fraction': 0.8585713056119598, 'bagging_fraction': 0.9420445160537261, 'bagging_freq': 2, 'min_child_samples': 72}. Best is trial 8 with value: 0.6352566666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8713127778926105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8713127778926105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9719475131384194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9719475131384194\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8713127778926105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8713127778926105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9719475131384194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9719475131384194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8713127778926105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8713127778926105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9719475131384194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9719475131384194\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8713127778926105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8713127778926105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9719475131384194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9719475131384194\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8713127778926105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8713127778926105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9719475131384194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9719475131384194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8713127778926105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8713127778926105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9719475131384194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9719475131384194\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8713127778926105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8713127778926105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9719475131384194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9719475131384194\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8713127778926105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8713127778926105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9719475131384194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9719475131384194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8713127778926105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8713127778926105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9719475131384194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9719475131384194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:29:46,302] Trial 10 finished with value: 0.6171633333333334 and parameters: {'num_leaves': 187, 'learning_rate': 0.2572065518176817, 'n_estimators': 450, 'max_depth': 16, 'feature_fraction': 0.8713127778926105, 'bagging_fraction': 0.9719475131384194, 'bagging_freq': 4, 'min_child_samples': 87}. Best is trial 8 with value: 0.6352566666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8736435853210897, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8736435853210897\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9604605648814097, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9604605648814097\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8736435853210897, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8736435853210897\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9604605648814097, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9604605648814097\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8736435853210897, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8736435853210897\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9604605648814097, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9604605648814097\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8736435853210897, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8736435853210897\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9604605648814097, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9604605648814097\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8736435853210897, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8736435853210897\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9604605648814097, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9604605648814097\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8736435853210897, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8736435853210897\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9604605648814097, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9604605648814097\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8736435853210897, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8736435853210897\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9604605648814097, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9604605648814097\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8736435853210897, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8736435853210897\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9604605648814097, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9604605648814097\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8736435853210897, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8736435853210897\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9604605648814097, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9604605648814097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:31:43,367] Trial 11 finished with value: 0.6327166666666666 and parameters: {'num_leaves': 181, 'learning_rate': 0.23821315922016117, 'n_estimators': 493, 'max_depth': 13, 'feature_fraction': 0.8736435853210897, 'bagging_fraction': 0.9604605648814097, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 8 with value: 0.6352566666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8701807163427753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8701807163427753\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9615420896344355, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9615420896344355\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8701807163427753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8701807163427753\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9615420896344355, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9615420896344355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8701807163427753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8701807163427753\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9615420896344355, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9615420896344355\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8701807163427753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8701807163427753\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9615420896344355, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9615420896344355\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8701807163427753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8701807163427753\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9615420896344355, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9615420896344355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8701807163427753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8701807163427753\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9615420896344355, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9615420896344355\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8701807163427753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8701807163427753\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9615420896344355, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9615420896344355\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8701807163427753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8701807163427753\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9615420896344355, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9615420896344355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8701807163427753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8701807163427753\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9615420896344355, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9615420896344355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:33:41,558] Trial 12 finished with value: 0.6346066666666667 and parameters: {'num_leaves': 181, 'learning_rate': 0.24161714836548376, 'n_estimators': 512, 'max_depth': 13, 'feature_fraction': 0.8701807163427753, 'bagging_fraction': 0.9615420896344355, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 8 with value: 0.6352566666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8741493441533292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8741493441533292\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9415148468180249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9415148468180249\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8741493441533292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8741493441533292\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9415148468180249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9415148468180249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8741493441533292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8741493441533292\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9415148468180249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9415148468180249\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8741493441533292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8741493441533292\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9415148468180249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9415148468180249\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8741493441533292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8741493441533292\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9415148468180249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9415148468180249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8741493441533292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8741493441533292\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9415148468180249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9415148468180249\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8741493441533292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8741493441533292\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9415148468180249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9415148468180249\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8741493441533292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8741493441533292\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9415148468180249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9415148468180249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8741493441533292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8741493441533292\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9415148468180249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9415148468180249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:35:56,454] Trial 13 finished with value: 0.6239466666666666 and parameters: {'num_leaves': 192, 'learning_rate': 0.2452725428664652, 'n_estimators': 518, 'max_depth': 13, 'feature_fraction': 0.8741493441533292, 'bagging_fraction': 0.9415148468180249, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 8 with value: 0.6352566666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8658513741583067, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8658513741583067\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9677995318369158, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9677995318369158\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8658513741583067, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8658513741583067\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9677995318369158, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9677995318369158\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8658513741583067, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8658513741583067\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9677995318369158, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9677995318369158\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8658513741583067, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8658513741583067\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9677995318369158, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9677995318369158\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8658513741583067, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8658513741583067\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9677995318369158, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9677995318369158\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8658513741583067, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8658513741583067\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9677995318369158, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9677995318369158\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8658513741583067, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8658513741583067\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9677995318369158, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9677995318369158\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8658513741583067, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8658513741583067\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9677995318369158, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9677995318369158\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8658513741583067, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8658513741583067\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9677995318369158, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9677995318369158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:37:51,185] Trial 14 finished with value: 0.63422 and parameters: {'num_leaves': 180, 'learning_rate': 0.268903320661625, 'n_estimators': 459, 'max_depth': 13, 'feature_fraction': 0.8658513741583067, 'bagging_fraction': 0.9677995318369158, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 8 with value: 0.6352566666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8835191534734327, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8835191534734327\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9458496096471842, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9458496096471842\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8835191534734327, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8835191534734327\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9458496096471842, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9458496096471842\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8835191534734327, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8835191534734327\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9458496096471842, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9458496096471842\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8835191534734327, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8835191534734327\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9458496096471842, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9458496096471842\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8835191534734327, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8835191534734327\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9458496096471842, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9458496096471842\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8835191534734327, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8835191534734327\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9458496096471842, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9458496096471842\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8835191534734327, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8835191534734327\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9458496096471842, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9458496096471842\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8835191534734327, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8835191534734327\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9458496096471842, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9458496096471842\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8835191534734327, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8835191534734327\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9458496096471842, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9458496096471842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:39:59,474] Trial 15 finished with value: 0.6252833333333333 and parameters: {'num_leaves': 188, 'learning_rate': 0.23205835318482104, 'n_estimators': 506, 'max_depth': 15, 'feature_fraction': 0.8835191534734327, 'bagging_fraction': 0.9458496096471842, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 8 with value: 0.6352566666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8656172764180496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8656172764180496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9672478836168793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9672478836168793\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8656172764180496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8656172764180496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9672478836168793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9672478836168793\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8656172764180496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8656172764180496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9672478836168793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9672478836168793\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8656172764180496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8656172764180496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9672478836168793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9672478836168793\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8656172764180496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8656172764180496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9672478836168793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9672478836168793\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8656172764180496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8656172764180496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9672478836168793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9672478836168793\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8656172764180496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8656172764180496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9672478836168793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9672478836168793\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8656172764180496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8656172764180496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9672478836168793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9672478836168793\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8656172764180496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8656172764180496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9672478836168793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9672478836168793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:42:11,657] Trial 16 finished with value: 0.6176866666666667 and parameters: {'num_leaves': 194, 'learning_rate': 0.24959148071197315, 'n_estimators': 483, 'max_depth': 15, 'feature_fraction': 0.8656172764180496, 'bagging_fraction': 0.9672478836168793, 'bagging_freq': 3, 'min_child_samples': 95}. Best is trial 8 with value: 0.6352566666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.879581601597795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.879581601597795\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9524699471568381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9524699471568381\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.879581601597795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.879581601597795\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9524699471568381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9524699471568381\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.879581601597795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.879581601597795\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9524699471568381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9524699471568381\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.879581601597795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.879581601597795\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9524699471568381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9524699471568381\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.879581601597795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.879581601597795\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9524699471568381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9524699471568381\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.879581601597795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.879581601597795\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9524699471568381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9524699471568381\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.879581601597795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.879581601597795\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9524699471568381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9524699471568381\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.879581601597795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.879581601597795\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9524699471568381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9524699471568381\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.879581601597795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.879581601597795\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9524699471568381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9524699471568381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:44:10,817] Trial 17 finished with value: 0.6285766666666667 and parameters: {'num_leaves': 202, 'learning_rate': 0.23398882714616812, 'n_estimators': 462, 'max_depth': 16, 'feature_fraction': 0.879581601597795, 'bagging_fraction': 0.9524699471568381, 'bagging_freq': 4, 'min_child_samples': 41}. Best is trial 8 with value: 0.6352566666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.894160778793932, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.894160778793932\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9328298007452813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9328298007452813\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.894160778793932, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.894160778793932\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9328298007452813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9328298007452813\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.894160778793932, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.894160778793932\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9328298007452813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9328298007452813\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.894160778793932, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.894160778793932\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9328298007452813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9328298007452813\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.894160778793932, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.894160778793932\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9328298007452813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9328298007452813\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.894160778793932, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.894160778793932\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9328298007452813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9328298007452813\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.894160778793932, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.894160778793932\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9328298007452813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9328298007452813\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.894160778793932, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.894160778793932\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9328298007452813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9328298007452813\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.894160778793932, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.894160778793932\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9328298007452813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9328298007452813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:46:13,997] Trial 18 finished with value: 0.6222666666666666 and parameters: {'num_leaves': 179, 'learning_rate': 0.26361137040010685, 'n_estimators': 506, 'max_depth': 13, 'feature_fraction': 0.894160778793932, 'bagging_fraction': 0.9328298007452813, 'bagging_freq': 3, 'min_child_samples': 56}. Best is trial 8 with value: 0.6352566666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8651406156647429, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8651406156647429\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642789701773024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642789701773024\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8651406156647429, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8651406156647429\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642789701773024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642789701773024\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8651406156647429, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8651406156647429\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642789701773024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642789701773024\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8651406156647429, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8651406156647429\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642789701773024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642789701773024\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8651406156647429, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8651406156647429\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642789701773024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642789701773024\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8651406156647429, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8651406156647429\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642789701773024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642789701773024\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8651406156647429, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8651406156647429\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642789701773024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642789701773024\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8651406156647429, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8651406156647429\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642789701773024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642789701773024\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8651406156647429, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8651406156647429\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642789701773024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642789701773024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:48:08,516] Trial 19 finished with value: 0.6321766666666666 and parameters: {'num_leaves': 185, 'learning_rate': 0.2496915011631563, 'n_estimators': 486, 'max_depth': 14, 'feature_fraction': 0.8651406156647429, 'bagging_fraction': 0.9642789701773024, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 8 with value: 0.6352566666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8791004440690343, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8791004440690343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9757032331426183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9757032331426183\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8791004440690343, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8791004440690343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9757032331426183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9757032331426183\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8791004440690343, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8791004440690343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9757032331426183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9757032331426183\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8791004440690343, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8791004440690343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9757032331426183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9757032331426183\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8791004440690343, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8791004440690343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9757032331426183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9757032331426183\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8791004440690343, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8791004440690343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9757032331426183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9757032331426183\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8791004440690343, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8791004440690343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9757032331426183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9757032331426183\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8791004440690343, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8791004440690343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9757032331426183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9757032331426183\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8791004440690343, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8791004440690343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9757032331426183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9757032331426183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:50:09,069] Trial 20 finished with value: 0.6371933333333334 and parameters: {'num_leaves': 190, 'learning_rate': 0.2890152737477537, 'n_estimators': 511, 'max_depth': 15, 'feature_fraction': 0.8791004440690343, 'bagging_fraction': 0.9757032331426183, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 20 with value: 0.6371933333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8776605037380006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8776605037380006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9778974124211404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9778974124211404\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8776605037380006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8776605037380006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9778974124211404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9778974124211404\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8776605037380006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8776605037380006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9778974124211404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9778974124211404\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8776605037380006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8776605037380006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9778974124211404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9778974124211404\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8776605037380006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8776605037380006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9778974124211404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9778974124211404\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8776605037380006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8776605037380006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9778974124211404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9778974124211404\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8776605037380006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8776605037380006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9778974124211404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9778974124211404\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8776605037380006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8776605037380006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9778974124211404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9778974124211404\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8776605037380006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8776605037380006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9778974124211404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9778974124211404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:52:10,768] Trial 21 finished with value: 0.6383166666666668 and parameters: {'num_leaves': 190, 'learning_rate': 0.2896887272881949, 'n_estimators': 510, 'max_depth': 15, 'feature_fraction': 0.8776605037380006, 'bagging_fraction': 0.9778974124211404, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 21 with value: 0.6383166666666668.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8802521339622115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8802521339622115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9799949149652878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9799949149652878\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8802521339622115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8802521339622115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9799949149652878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9799949149652878\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8802521339622115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8802521339622115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9799949149652878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9799949149652878\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8802521339622115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8802521339622115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9799949149652878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9799949149652878\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8802521339622115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8802521339622115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9799949149652878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9799949149652878\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8802521339622115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8802521339622115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9799949149652878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9799949149652878\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8802521339622115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8802521339622115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9799949149652878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9799949149652878\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8802521339622115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8802521339622115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9799949149652878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9799949149652878\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8802521339622115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8802521339622115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9799949149652878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9799949149652878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:54:14,154] Trial 22 finished with value: 0.6379400000000001 and parameters: {'num_leaves': 190, 'learning_rate': 0.2878863018587207, 'n_estimators': 508, 'max_depth': 15, 'feature_fraction': 0.8802521339622115, 'bagging_fraction': 0.9799949149652878, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 21 with value: 0.6383166666666668.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8894893030552147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8894893030552147\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9797070603005562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9797070603005562\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8894893030552147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8894893030552147\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9797070603005562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9797070603005562\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8894893030552147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8894893030552147\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9797070603005562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9797070603005562\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8894893030552147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8894893030552147\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9797070603005562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9797070603005562\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8894893030552147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8894893030552147\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9797070603005562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9797070603005562\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8894893030552147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8894893030552147\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9797070603005562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9797070603005562\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8894893030552147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8894893030552147\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9797070603005562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9797070603005562\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8894893030552147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8894893030552147\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9797070603005562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9797070603005562\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8894893030552147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8894893030552147\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9797070603005562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9797070603005562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:56:23,967] Trial 23 finished with value: 0.63475 and parameters: {'num_leaves': 197, 'learning_rate': 0.28989869571556764, 'n_estimators': 510, 'max_depth': 16, 'feature_fraction': 0.8894893030552147, 'bagging_fraction': 0.9797070603005562, 'bagging_freq': 4, 'min_child_samples': 40}. Best is trial 21 with value: 0.6383166666666668.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8809124435056035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8809124435056035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9750379780330455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9750379780330455\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8809124435056035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8809124435056035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9750379780330455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9750379780330455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8809124435056035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8809124435056035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9750379780330455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9750379780330455\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8809124435056035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8809124435056035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9750379780330455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9750379780330455\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8809124435056035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8809124435056035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9750379780330455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9750379780330455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8809124435056035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8809124435056035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9750379780330455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9750379780330455\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8809124435056035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8809124435056035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9750379780330455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9750379780330455\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8809124435056035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8809124435056035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9750379780330455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9750379780330455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2633\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8809124435056035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8809124435056035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9750379780330455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9750379780330455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 10:58:27,519] Trial 24 finished with value: 0.63877 and parameters: {'num_leaves': 200, 'learning_rate': 0.28895282410037054, 'n_estimators': 502, 'max_depth': 15, 'feature_fraction': 0.8809124435056035, 'bagging_fraction': 0.9750379780330455, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 24 with value: 0.63877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by Optuna: {'num_leaves': 200, 'learning_rate': 0.28895282410037054, 'n_estimators': 502, 'max_depth': 15, 'feature_fraction': 0.8809124435056035, 'bagging_fraction': 0.9750379780330455, 'bagging_freq': 4, 'min_child_samples': 27}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X_train = X_train[:300000]\n",
    "y_train = y_train[:300000]\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 3,\n",
    "        'metric': 'multi_logloss',\n",
    "        # Range più stretti attorno al best value trovato\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 170, 210),        # attorno a 189\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.22, 0.29),   # attorno a 0.26\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 450, 520),    # attorno a 491\n",
    "        'max_depth': trial.suggest_int('max_depth', 13, 17),            # attorno a 15\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.85, 0.92),  # attorno a 0.88\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.92, 0.98),  # attorno a 0.95\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 2, 4),         # attorno a 3\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 20, 100),     # opzionale, per robustezza\n",
    "        'class_weight': 'balanced',\n",
    "        'random_state': 42\n",
    "    }\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        model = LGBMClassifier(**param)\n",
    "        model.fit(X_train.iloc[train_idx], y_train.iloc[train_idx])\n",
    "        score = model.score(X_train.iloc[val_idx], y_train.iloc[val_idx])\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=25)\n",
    "print(\"Best parameters found by Optuna:\", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298340ee",
   "metadata": {},
   "source": [
    "### Final model training with best hyperparameters from Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "32bf8e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (965606, 12)\n",
      "Test set size: (241402, 12)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.20, random_state=42\n",
    ")\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "print(\"Train set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "14d15379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8809124435056035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8809124435056035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9750379780330455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9750379780330455\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8809124435056035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8809124435056035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9750379780330455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9750379780330455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2630\n",
      "[LightGBM] [Info] Number of data points in the train set: 965606, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8809124435056035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8809124435056035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9750379780330455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9750379780330455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Low Trend       0.88      0.74      0.81    134887\n",
      "Medium Trend       0.58      0.70      0.64     53970\n",
      "  High Trend       0.63      0.76      0.69     52545\n",
      "\n",
      "    accuracy                           0.74    241402\n",
      "   macro avg       0.70      0.73      0.71    241402\n",
      "weighted avg       0.76      0.74      0.74    241402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "best_params.update({'objective': 'multiclass', 'num_class': 3, 'class_weight': 'balanced', 'random_state': 42})\n",
    "model = LGBMClassifier(**best_params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(\n",
    "    y_test, y_pred, target_names=['Low Trend', 'Medium Trend', 'High Trend']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7fd1ca72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            feature  importance_pct\n",
      "11      category_id       22.300747\n",
      "10  slm pressure mb       13.804748\n",
      "3       max temp °C        8.825335\n",
      "6     visibility km        8.203034\n",
      "5        humidity %        7.821311\n",
      "4      dew point °C        7.248727\n",
      "1       avg temp °C        7.106916\n",
      "7     avg wind km/h        6.723191\n",
      "8     max wind km/h        6.718520\n",
      "2       min temp °C        6.708176\n",
      "0          locality        2.890615\n",
      "9         gust km/h        1.648682\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcola la feature importance\n",
    "importances = model.feature_importances_\n",
    "feature_imp = pd.DataFrame({\n",
    "    \"feature\": X.columns,\n",
    "    \"importance\": importances\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "# Calcola la percentuale di importanza di ciascuna feature\n",
    "feature_imp[\"importance_pct\"] = 100 * feature_imp[\"importance\"] / feature_imp[\"importance\"].sum()\n",
    "\n",
    "# Visualizza con valori percentuali arrotondati\n",
    "print(feature_imp[[\"feature\", \"importance_pct\"]])\n",
    "\n",
    "# (Facoltativo) Grafico a barre percentuale\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(feature_imp[\"feature\"], feature_imp[\"importance_pct\"])\n",
    "plt.xlabel(\"Importance (%)\")\n",
    "plt.title(\"Feature Importance (percentuale) - LightGBM\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffed31a",
   "metadata": {},
   "source": [
    "### Save the Model and Processed Dataset\n",
    "\n",
    "Export the fused dataset and, if needed, the trained model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "82f3dea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/output/trend_weather_forecast/lgbm.joblib']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the merged dataset with features and label\n",
    "df.to_parquet('./data/output/trend_weather_forecast/trend_weather_fusion_labeled.parquet', index=False)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, './data/output/trend_weather_forecast/lgbm.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e118fbd",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You have created a weekly-level multimodal dataset joining Google Trends and weather data, engineered features, \n",
    "labeled the target with three trend classes, and trained/evaluated a baseline random forest classifier.\n",
    "\n",
    "This dataset and model can now be used as the first layer in your ensemble architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d00240",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
